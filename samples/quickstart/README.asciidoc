= Celos Quickstart Example

This small example shows how to set up a simple Celos installation and
run a MapReduce wordcount workflow.  It is intended to show you the
ropes of working with Celos, and not as an example of creating a
production-ready workflow or Celos setup. For that, please check out
the rest of the Celos documentation.

== Build Celos

In the Celos repository *root directory* do the following to build the
required JARs:

....
scripts/build.sh
....

Then switch to the *samples/quickstart* directory:

....
cd samples/quickstart
....

== Create directories required by Celos

We're creating a *samples/quickstart/celos.d* directory that holds all
the directories required by Celos to run:

* A *workflows* directory containing the JavaScript workflow files.
* A *defaults* directory containing the JavaScript defaults files.
* A *logs* directory containing the Celos log outputs.
* A *db* directory containing Celos' state database.

....
mkdir celos.d
mkdir celos.d/workflows
mkdir celos.d/defaults
mkdir celos.d/logs
mkdir celos.d/db
....

== Edit the defaults.js file

Open *src/main/celos/defaults.js* in an editor and update the settings
at the top for your Hadoop and Oozie installation.

== Copy the JavaScript files to the proper directories

....
cp src/main/celos/workflow.js celos.d/workflows/wordcount.js
cp src/main/celos/defaults.js celos.d/defaults/quickstart-settings.js
....

== Build the workflow JAR

Compile the Java code in *src/main/java* and produce the JAR in
*build/libs/wordcount-1.0.jar*

....
./gradlew jar
....

== Upload the workflow.xml file and JAR to HDFS

....
export USER=manuel # Change to your Hadoop username
hadoop fs -mkdir -p /user/$USER/celos/quickstart/app/lib
hadoop fs -put -f src/main/oozie/workflow.xml /user/$USER/celos/quickstart/app/workflow.xml
hadoop fs -put -f build/libs/wordcount-1.0.jar /user/$USER/celos/quickstart/app/lib
....

== Upload the sample inputs to HDFS

....
hadoop fs -put src/test/resources/input /user/$USER/celos/quickstart/input
....

== Start Celos

....
export CELOS_PORT=11337 # Adapt if needed
export CELOS=http://localhost:$CELOS_PORT
export CLASSPATH=../../celos-server/build/libs/celos-server.jar:/etc/hadoop/conf
java -cp $CLASSPATH com.collective.celos.server.Main --port $CELOS_PORT --workows celos.d/workflows --defaults celos.d/defaults --logs celos.cd/logs --db celos.d/db --autoSchedule 5 > /dev/null 2>&1 &
....

== Check that Celos has loaded the wordcount workflow

Do the following:

....
curl $CELOS/workflow-list
....

This should print the following:

....
{
  "ids" : [ "wordcount" ]
}
....

== Mark inputs for rerun

By default, Celos will only look at the slots within a 7 day sliding
window before the current time.

To have Celos care about the input data do the following:

....
curl -X POST "$CELOS/rerun?id=wordcount&time=2015-09-01T00:00Z"
curl -X POST "$CELOS/rerun?id=wordcount&time=2015-09-01T01:00Z"
curl -X POST "$CELOS/rerun?id=wordcount&time=2015-09-01T02:00Z"
....

== Open the UI

....
export HUE=http://cldmgr001.ewr004.collective-media.net:8888/oozie # Point to your Oozie UI
java -jar ../../celos-ui/build/libs/celos-ui.jar --port 11338 --celos $CELOS --hue $HUE
....

Now go to this URL in your browser:

....
http://localhost:11338/ui?time=2015-09-02T00:00Z
....

You should see three ready or running slots.  You can click on a
running slot to see its Oozie information.

== Look at MapReduce outputs in HDFS

After a while, when all slots are green, you can look at the results in HDFS:

....
hadoop fs -cat /user/$USER/celos/quickstart/output/2015-09-01/0000/part-00000
....
